{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "constant-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 The call girl wasted the money . 3\n",
      "1 The money wasted the call girl . 2\n",
      "2 The money was wasted by the call girl . 3\n",
      "3 The call girl was wasted by the money . 4\n",
      "4 The ship captain promised the triumph . 3\n",
      "5 The triumph promised the ship captain . 2\n",
      "6 The triumph was promised by the ship captain . 3\n",
      "7 The ship captain was promised by the triumph . 4\n",
      "8 The drapes were suggested by the designer . 3\n",
      "9 The designer was suggested by the drapes . 3\n",
      "10 The curtains were recommended by the decorator . 3\n",
      "11 The decorator was recommended by the curtains . 3\n",
      "12 The builder were washed by the pants . 3\n",
      "13 The contractor was laundered by the trousers . 3\n",
      "14 The domestic cleaned the wash basin . 2\n",
      "15 The wash basin cleaned the domestic . 3\n",
      "16 The wash basin was cleaned by the domestic . 4\n",
      "17 The domestic was cleaned by the wash basin . 3\n",
      "18 The logger felled the pine tree . 2\n",
      "19 The pine tree felled the logger . 3\n",
      "20 The pine tree was felled by the logger . 4\n",
      "21 The logger was felled by the pine tree . 3\n",
      "22 The proprietor dislodged the renter . 2\n",
      "23 The renter dislodged the proprietor . 2\n",
      "24 The renter was dislodged by the proprietor . 3\n",
      "25 The proprietor was dislodged by the renter . 3\n",
      "26 The hit man killed the politician . 3\n",
      "27 The politician killed the hit man . 2\n",
      "28 The politician was killed by the hit man . 3\n",
      "29 The hit man was killed by the politician . 4\n",
      "30 The clerk charged the elderly person . 2\n",
      "31 The elderly person charged the clerk . 3\n",
      "32 The elderly person was charged by the clerk . 4\n",
      "33 The clerk was charged by the elderly person . 3\n",
      "34 The cashier billed the senior citizen . 2\n",
      "35 The senior citizen billed the cashier . 3\n",
      "36 The senior citizen was billed by the cashier . 4\n",
      "37 The cashier was billed by the senior citizen . 3\n",
      "38 The orator was captivated by the spectators . 3\n",
      "39 The amateur irked the maestro . 2\n",
      "40 The maestro irked the amateur . 2\n",
      "41 The maestro was irked by the amateur . 3\n",
      "42 The amateur was irked by the maestro . 3\n",
      "43 The viewers were entranced by the illusionist . 3\n",
      "44 The illusionist was entranced by the viewers . 3\n",
      "45 The terrorist petrified the first lady . 2\n",
      "46 The first lady petrified the terrorist . 3\n",
      "47 The first lady was petrified by the terrorist . 4\n",
      "48 The terrorist was petrified by the first lady . 3\n",
      "49 The hijacker terrified the president's wife . 2\n",
      "50 The president's wife terrified the hijacker . 3\n",
      "51 The president's wife was terrified by the hijacker . 4\n",
      "52 The hijacker was terrified by the president's wife . 3\n",
      "53 The judge praised the gold medalist . 2\n",
      "54 The gold medalist praised the judge . 3\n",
      "55 The gold medalist was praised by the judge . 4\n",
      "56 The judge was praised by the gold medalist . 3\n",
      "57 The ancestors were idolized by the peasant . 3\n",
      "58 The peasant were idolized by the ancestors . 3\n",
      "59 The forefathers were worshipped by the serf . 3\n",
      "60 The serf were worshipped by the forefathers . 3\n",
      "61 The traveling salesman challenged the executive . 3\n",
      "62 The executive challenged the traveling salesman . 2\n",
      "63 The executive was challenged by the traveling salesman . 3\n",
      "64 The traveling salesman was challenged by the executive . 4\n",
      "65 The instrumentalist adored the prima donna . 2\n",
      "66 The prima donna adored the instrumentalist . 3\n",
      "67 The prima donna was adored by the instrumentalist . 4\n",
      "68 The instrumentalist was adored by the prima donna . 3\n",
      "69 The residents were angered by the dictator . 3\n",
      "70 The dictator was angered by the residents . 3\n",
      "71 The townspeople were enraged by the despot . 3\n",
      "72 The despot was enraged by the townspeople . 3\n",
      "73 The refugee provoked the homeless person . 2\n",
      "74 The homeless person provoked the refugee . 3\n",
      "75 The homeless person was provoked by the refugee . 4\n",
      "76 The refugee was provoked by the homeless person . 3\n",
      "77 The asylum seeker goaded the vagrant . 3\n",
      "78 The vagrant goaded the asylum seeker . 2\n",
      "79 The vagrant was goaded by the asylum seeker . 3\n",
      "80 The asylum seeker was goaded by the vagrant . 4\n",
      "81 The runner encountered the co-worker . 2\n",
      "82 The co-worker encountered the runner . 2\n",
      "83 The co-worker was encountered by the runner . 3\n",
      "84 The runner was encountered by the co-worker . 3\n",
      "89 The postal worker repulsed the taxi-driver . 3\n",
      "90 The taxi-driver repulsed the postal worker . 2\n",
      "91 The taxi-driver was repulsed by the postal worker . 3\n",
      "92 The postal worker was repulsed by the taxi-driver . 4\n",
      "93 The letter carrier disgusted the cabbie . 3\n",
      "94 The cabbie disgusted the letter carrier . 2\n",
      "95 The cabbie was disgusted by the letter carrier . 3\n",
      "96 The letter carrier was disgusted by the cabbie . 4\n",
      "97 The officer were alerted by the authorities . 3\n",
      "98 The deputy was notified by the higher-ups . 3\n",
      "99 The perpetrator exposed the poacher . 2\n",
      "100 The poacher exposed the perpetrator . 2\n",
      "101 The poacher was exposed by the perpetrator . 3\n",
      "102 The perpetrator was exposed by the poacher . 3\n",
      "103 The flora specialist esteemed the collaborator . 3\n",
      "104 The collaborator esteemed the flora specialist . 2\n",
      "105 The collaborator was esteemed by the flora specialist . 3\n",
      "106 The flora specialist was esteemed by the collaborator . 4\n",
      "107 The rogue defeated the main character . 2\n",
      "108 The main character defeated the rogue . 3\n",
      "109 The main character was defeated by the rogue . 4\n",
      "110 The rogue was defeated by the main character . 3\n",
      "117 The rules were emphasized by the counselor . 3\n",
      "118 The counselor was emphasized by the rules . 3\n",
      "123 The laundress were folded by the clothes . 3\n",
      "124 The groundskeeper changed the light bulb . 2\n",
      "125 The light bulb changed the groundskeeper . 3\n",
      "126 The light bulb was changed by the groundskeeper . 4\n",
      "127 The groundskeeper was changed by the light bulb . 3\n",
      "128 The house sitter watered the plant . 3\n",
      "129 The plant watered the house sitter . 2\n",
      "130 The plant was watered by the house sitter . 3\n",
      "131 The house sitter was watered by the plant . 4\n",
      "132 The twins were punished by the babysitter . 3\n",
      "133 The babysitter was punished by the twins . 3\n",
      "134 The barber shaved the old man . 2\n",
      "135 The old man shaved the barber . 3\n",
      "136 The old man was shaved by the barber . 4\n",
      "137 The barber was shaved by the old man . 3\n",
      "138 The paparazzi stalked the pop star . 2\n",
      "139 The pop star stalked the paparazzi . 3\n",
      "140 The pop star was stalked by the paparazzi . 4\n",
      "141 The paparazzi was stalked by the pop star . 3\n",
      "142 The personal trainer weighed the Olympian . 3\n",
      "143 The Olympian weighed the personal trainer . 2\n",
      "144 The Olympian was weighed by the personal trainer . 3\n",
      "145 The personal trainer was weighed by the Olympian . 4\n",
      "146 The tennis player thanked the chiropractor . 3\n",
      "147 The chiropractor thanked the tennis player . 2\n",
      "148 The chiropractor was thanked by the tennis player . 3\n",
      "149 The tennis player was thanked by the chiropractor . 4\n",
      "150 The assistant principal expelled the sociopath . 3\n",
      "151 The sociopath expelled the assistant principal . 2\n",
      "152 The sociopath was expelled by the assistant principal . 3\n",
      "153 The assistant principal was expelled by the sociopath . 4\n",
      "154 The au pair spanked the girl . 3\n",
      "155 The girl spanked the au pair . 2\n",
      "156 The girl was spanked by the au pair . 3\n",
      "157 The au pair was spanked by the girl . 4\n",
      "158 The TV station head promoted the newsagent . 4\n",
      "159 The newsagent promoted the TV station head . 2\n",
      "160 The newsagent was promoted by the TV station head . 3\n",
      "161 The TV station head was promoted by the newsagent . 5\n",
      "162 The police chief rewarded the firefighter . 3\n",
      "163 The firefighter rewarded the police chief . 2\n",
      "164 The firefighter was rewarded by the police chief . 3\n",
      "165 The police chief was rewarded by the firefighter . 4\n",
      "166 The social worker comforted the abused woman . 3\n",
      "166 The social worker comforted the abused woman . 5\n",
      "167 The abused woman comforted the social worker . 1\n",
      "167 The abused woman comforted the social worker . 3\n",
      "168 The abused woman was comforted by the social worker . 1\n",
      "168 The abused woman was comforted by the social worker . 4\n",
      "169 The social worker was comforted by the abused woman . 4\n",
      "169 The social worker was comforted by the abused woman . 7\n",
      "170 The neuroscientist overwhelmed the lab assistant . 2\n",
      "171 The lab assistant overwhelmed the neuroscientist . 3\n",
      "172 The lab assistant was overwhelmed by the neuroscientist . 4\n",
      "173 The neuroscientist was overwhelmed by the lab assistant . 3\n",
      "174 The football player pursued the socialite . 3\n",
      "175 The socialite pursued the football player . 2\n",
      "176 The socialite was pursued by the football player . 3\n",
      "177 The football player was pursued by the socialite . 4\n",
      "178 The fashionista humiliated the model . 2\n",
      "179 The model humiliated the fashionista . 2\n",
      "180 The model was humiliated by the fashionista . 3\n",
      "181 The fashionista was humiliated by the model . 3\n",
      "182 The claims adjuster harassed the retailer . 3\n",
      "183 The retailer harassed the claims adjuster . 2\n",
      "184 The retailer was harassed by the claims adjuster . 3\n",
      "185 The claims adjuster was harassed by the retailer . 4\n",
      "186 The cinematographer favored the movie star . 2\n",
      "187 The movie star favored the cinematographer . 3\n",
      "188 The movie star was favored by the cinematographer . 4\n",
      "189 The cinematographer was favored by the movie star . 3\n",
      "190 The hockey player aggravated the skater . 3\n",
      "191 The skater aggravated the hockey player . 2\n",
      "192 The skater was aggravated by the hockey player . 3\n",
      "193 The hockey player was aggravated by the skater . 4\n",
      "194 The bricklayer outraged the crane operator . 2\n",
      "195 The crane operator outraged the bricklayer . 3\n",
      "196 The crane operator was outraged by the bricklayer . 4\n",
      "197 The bricklayer was outraged by the crane operator . 3\n"
     ]
    }
   ],
   "source": [
    "sentences = open('originals/new-EventsAdapt-sentences.txt', 'r').readlines()\n",
    "for i, sent in enumerate(sentences):\n",
    "    s = sent.strip().split(' ')\n",
    "    for p, w in enumerate(s):\n",
    "        if w.endswith('ed'):\n",
    "            print(i, sent.strip(), p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-middle",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "(You must adapt this part to your dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intelligent-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function load the datasets modified, the 3rd column is the position of the word we have to mask\n",
    "def load_data(inpath):\n",
    "    idxs = []\n",
    "    sentences = []\n",
    "    pos = []\n",
    "    with open(inpath, 'r') as f:\n",
    "        for line in f:\n",
    "            idx, sentence, target_pos = line.strip().split('\\t')\n",
    "            idxs.append(idx)\n",
    "            sentences.append(sentence)\n",
    "            pos.append(int(target_pos))\n",
    "    return idxs, sentences, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "designing-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset new-EventsAdapt-sentences.ids.txt\n",
    "idxs_sent, sentences, pos = load_data('originals/new-EventsAdapt-sentences.ids.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f417482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function load for word2word mask tasks\n",
    "def prepare_data(df):\n",
    "    ids = []\n",
    "    sents = []\n",
    "    for index, row in df.iterrows():\n",
    "        ids.append(row[0])\n",
    "        if row[1][-1]!='.':\n",
    "            sents.append(row[1]+' .')\n",
    "        else:\n",
    "            sents.append(row[1])\n",
    "    return (ids, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fa7c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load just ids and sentences (for word-by-word preds)\n",
    "dtfit=pd.read_csv('originals/DTFit_vassallo_deps.txt', sep='\\t', header=None)\n",
    "ev1=pd.read_csv('originals/ev1_deps.txt', sep='\\t',header=None)\n",
    "ev2=pd.read_csv('originals/ev2_deps.txt', sep='\\t',header=None)\n",
    "new_ev=pd.read_csv('originals/new-EventsAdapt-sentences.ids.txt', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f683f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ev=pd.read_csv('originals/new-EventsAdapt-sentences.ids.txt', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69cf92c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The actor won the battle</td>\n",
       "      <td>animate-inanimate</td>\n",
       "      <td>AT</td>\n",
       "      <td>actor:nsubj win:root battle:obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The actor won the award</td>\n",
       "      <td>animate-inanimate</td>\n",
       "      <td>T</td>\n",
       "      <td>actor:nsubj win:root award:obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The anchorman told the parable</td>\n",
       "      <td>animate-inanimate</td>\n",
       "      <td>AT</td>\n",
       "      <td>anchorman:nsubj tell:root parable:obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The anchorman told the news</td>\n",
       "      <td>animate-inanimate</td>\n",
       "      <td>T</td>\n",
       "      <td>anchorman:nsubj tell:root news:obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The animal found the map</td>\n",
       "      <td>animate-inanimate</td>\n",
       "      <td>AT</td>\n",
       "      <td>animal:nsubj find:root map:obj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                               1                  2   3  \\\n",
       "0  0        The actor won the battle  animate-inanimate  AT   \n",
       "1  1         The actor won the award  animate-inanimate   T   \n",
       "2  2  The anchorman told the parable  animate-inanimate  AT   \n",
       "3  3     The anchorman told the news  animate-inanimate   T   \n",
       "4  4        The animal found the map  animate-inanimate  AT   \n",
       "\n",
       "                                        4  \n",
       "0        actor:nsubj win:root battle:obj   \n",
       "1         actor:nsubj win:root award:obj   \n",
       "2  anchorman:nsubj tell:root parable:obj   \n",
       "3     anchorman:nsubj tell:root news:obj   \n",
       "4         animal:nsubj find:root map:obj   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtfit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9addadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {'ev1': prepare_data(ev1),\n",
    "            'dtfit': prepare_data(dtfit),\n",
    "            'ev2': prepare_data(ev2),\n",
    "            'new-EventsAdapt': prepare_data(new_ev)\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-figure",
   "metadata": {},
   "source": [
    "## Transformer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comic-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tokenizations   #   pip install pytokenizations  (https://pypi.org/project/pytokenizations/)\n",
    "import tensorflow as tf  #  TensorFlow 2.0 is required (Python 3.5-3.7, Pip 19.0 or later)\n",
    "\n",
    "import sentencepiece as spm\n",
    "from transformers import BertTokenizer, TFBertForMaskedLM\n",
    "from transformers import RobertaTokenizer, TFRobertaForMaskedLM\n",
    "from transformers import XLNetTokenizer, TFXLNetLMHeadModel\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f30e0ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-large-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaForMaskedLM.\n",
      "\n",
      "All the layers of TFRobertaForMaskedLM were initialized from the model checkpoint at roberta-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForMaskedLM for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFXLNetLMHeadModel.\n",
      "\n",
      "All the layers of TFXLNetLMHeadModel were initialized from the model checkpoint at xlnet-large-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetLMHeadModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "N_PREDICTIONS = 15\n",
    "\n",
    "dict_tokenizers = {\"bert-base-cased\": BertTokenizer.from_pretrained('bert-base-cased'),\n",
    "                   \"bert-large-cased\": BertTokenizer.from_pretrained('bert-large-cased'),\n",
    "                   \"roberta-large\": RobertaTokenizer.from_pretrained('roberta-large'),\n",
    "                   \"xlnet-large-cased\":XLNetTokenizer.from_pretrained('xlnet-large-cased'),\n",
    "                   \"gpt2-medium\": GPT2Tokenizer.from_pretrained('gpt2-medium')}\n",
    "\n",
    "\n",
    "dict_mlm_models = {\"bert-base-cased\": TFBertForMaskedLM.from_pretrained('bert-base-cased'),\n",
    "                   \"bert-large-cased\": TFBertForMaskedLM.from_pretrained('bert-large-cased'),\n",
    "                   \"roberta-large\": TFRobertaForMaskedLM.from_pretrained('roberta-large'),\n",
    "                   \"xlnet-large-cased\":TFXLNetLMHeadModel.from_pretrained('xlnet-large-cased'),\n",
    "                   \"gpt2-medium\": TFGPT2LMHeadModel.from_pretrained('gpt2-medium')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "professional-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel:\n",
    "    \n",
    "    def __init__(self, transf_model):\n",
    "        self.model_name = transf_model\n",
    "        self.tokenizer = dict_tokenizers[transf_model]\n",
    "        self.mlm_model = dict_mlm_models[transf_model]\n",
    "        \n",
    "    def prepare_input(self, sentences, pos_ids):\n",
    "        target_tokens = []\n",
    "        sentences_with_mask = []\n",
    "        dependents_indices = []\n",
    "        #sentences = sentences.reset_index(drop=True)\n",
    "        for i in range(len(sentences)):\n",
    "            sent = sentences[i]\n",
    "            id_dep = pos_ids[i]\n",
    "            s = sent.split(\" \")\n",
    "            #print(s, id_dep)\n",
    "            target_token = sent.split(\" \")[id_dep]\n",
    "            \n",
    "            #  check if target token is in dictionary - otherwise add None to the lists     \n",
    "            # BERT\n",
    "            if self.model_name.startswith(\"bert\"):\n",
    "                if self.tokenizer.convert_ids_to_tokens(self.tokenizer.convert_tokens_to_ids(target_token)) == \"[UNK]\":\n",
    "                    #target_tokens.append(None)\n",
    "                    target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                else:\n",
    "                    target_tokens.append(target_token)\n",
    "            \n",
    "            # RoBERTa\n",
    "            if self.model_name.startswith(\"roberta\"):\n",
    "                if id_dep == 0:\n",
    "                    if self.tokenizer.convert_ids_to_tokens(self.tokenizer.convert_tokens_to_ids(target_token)) == \\\n",
    "                            \"<unk>\":\n",
    "                        #target_tokens.append(None)\n",
    "                        target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                    else:\n",
    "                        target_tokens.append(target_token)\n",
    "                else:\n",
    "                    if self.tokenizer.convert_ids_to_tokens(self.tokenizer.convert_tokens_to_ids(\"Ġ\"+target_token)) == \\\n",
    "                            \"<unk>\":\n",
    "                        #target_tokens.append(None)\n",
    "                        target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                    else:\n",
    "                        target_tokens.append(\"Ġ\"+target_token)\n",
    "                        \n",
    "            if self.model_name.startswith(\"xlnet\"):\n",
    "                if self.tokenizer.convert_ids_to_tokens(self.tokenizer.convert_tokens_to_ids(u\"\\u2581\"+target_token)) == \\\n",
    "                            \"<unk>\":\n",
    "                    #target_tokens.append(None)\n",
    "                    target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                else:\n",
    "                    target_tokens.append(u\"\\u2581\"+target_token)\n",
    "                    #since in sentencepiece tokenizer this symbol is used for whitespace\n",
    "                        \n",
    "            # GPT-2\n",
    "            if self.model_name.startswith(\"gpt\"):\n",
    "                if id_dep == 0:\n",
    "                    if self.tokenizer.convert_ids_to_tokens(\n",
    "                            self.tokenizer.convert_tokens_to_ids(target_token)) == \"<|endoftext|>\":\n",
    "                        #target_tokens.append(None)\n",
    "                        target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                    else:\n",
    "                        target_tokens.append(target_token)\n",
    "                else:\n",
    "                    if self.tokenizer.convert_ids_to_tokens(\n",
    "                            self.tokenizer.convert_tokens_to_ids(\"Ġ\" + target_token)) == \"<|endoftext|>\":\n",
    "                        #target_tokens.append(None)\n",
    "                        target_tokens.append(self.tokenizer.tokenize(target_token))\n",
    "                    else:\n",
    "                        target_tokens.append(\"Ġ\" + target_token)\n",
    "                        \n",
    "            # mask the sentence\n",
    "            list_words = []\n",
    "            for w in range(len(sent.split(\" \"))):\n",
    "                if w != id_dep:\n",
    "                    list_words.append(sent.split(\" \")[w])\n",
    "                else:\n",
    "                    if self.model_name.startswith(\"bert\"):\n",
    "                        list_words.append(\"[MASK]\")\n",
    "                    if self.model_name.startswith((\"roberta\", 'xlnet')):\n",
    "                        list_words.append(\"<mask>\")\n",
    "                    if self.model_name.startswith(\"gpt\"):\n",
    "                        list_words.append(sent.split(\" \")[w])  #  mask is not needed for gpt\n",
    "            masked_sent = \" \".join(list_words)\n",
    "            sentences_with_mask.append(masked_sent)\n",
    "            \n",
    "            model_tokenization = self.tokenizer.tokenize(masked_sent)\n",
    "            #print(model_tokenization)\n",
    "            \n",
    "            if self.model_name.startswith(\"bert\"):\n",
    "                dependent_index = model_tokenization.index(\"[MASK]\") + 1  # take into account token [CLS]\n",
    "            if self.model_name.startswith(\"roberta\"):\n",
    "                dependent_index = model_tokenization.index(\"<mask>\") + 1\n",
    "            if self.model_name.startswith(\"gpt\"):\n",
    "                our_tokenization = masked_sent.split(\" \")\n",
    "                other_tokens_2_model_tokens, model_tokens_2_other_tokens = tokenizations.\\\n",
    "                    get_alignments(our_tokenization, model_tokenization)\n",
    "                dependent_index = other_tokens_2_model_tokens[id_dep][0] + 1\n",
    "            if self.model_name.startswith(\"xlnet\"):\n",
    "                dependent_index = model_tokenization.index(\"<mask>\") \n",
    "                #since xlnet tokenizer does not add cls token at the beginning of the sequence\n",
    "                \n",
    "            dependents_indices.append(dependent_index)\n",
    "            i += 1\n",
    "        return target_tokens, sentences_with_mask, dependents_indices\n",
    "    \n",
    "    def compute_filler_probability(self, list_target_words, list_masked_sentences, \\\n",
    "                                   list_dependents_indexes, unidirectional=False):\n",
    "        \n",
    "        if self.model_name.startswith(\"gpt\"):\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            inputs = self.tokenizer([\"<|endoftext|>\" + sent + \"<|endoftext|>\" for sent in list_masked_sentences],\n",
    "                                    padding=True, return_tensors=\"tf\")\n",
    "            # it is necessary to add a token at the beginning of the sentence\n",
    "        elif self.model_name.startswith(\"xlnet\"):\n",
    "            self.tokenizer.padding_side = \"right\" #since instances of xlnet tokenizer by default apply padding to the left\n",
    "            inputs = self.tokenizer(list_masked_sentences, padding=True, return_tensors=\"tf\") \n",
    "        else:\n",
    "            inputs = self.tokenizer(list_masked_sentences, padding=True, return_tensors=\"tf\")\n",
    "            \n",
    "        if not unidirectional:\n",
    "            probabilities_fillers = []\n",
    "            predicted_fillers = []\n",
    "\n",
    "            #print(\"Executing model for batch...\")\n",
    "            #print()\n",
    "            outputs = self.mlm_model(inputs)[0]\n",
    "            for batch_elem, target_word, dep_index in zip(range(outputs.shape[0]), list_target_words,\n",
    "                                                          list_dependents_indexes):\n",
    "                #if target_word is None:\n",
    "                    #probabilities_fillers.append(None)\n",
    "                    #predicted_fillers.append(None)\n",
    "                if type(target_word) == list: # word is OOV, get its subcomponents probability and average them\n",
    "                    prob_subwords = []\n",
    "                    for target_subword in target_word:\n",
    "                        if (self.model_name.startswith(\"bert\")) or (self.model_name.startswith(\"roberta\")):\n",
    "                            all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index]).numpy()\n",
    "                        if self.model_name.startswith(\"gpt\") or self.model_name.startswith(\"xlnet\"):\n",
    "                            all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index - 1]).numpy()\n",
    "                        \n",
    "                        prob_subwords.append(all_probabilities[self.tokenizer.convert_tokens_to_ids(target_subword)])\n",
    "                    #print(probabilities_fillers, prob_subwords, sum(prob_subwords)/len(prob_subwords))\n",
    "                    probabilities_fillers.append(sum(prob_subwords)/len(prob_subwords))\n",
    "                    #idxs_predictions = (-(np.array(all_probabilities))).argsort()[:N_PREDICTIONS]\n",
    "                    #predictions = self.tokenizer.convert_ids_to_tokens([int(index) for index in idxs_predictions])\n",
    "                        \n",
    "                else:\n",
    "                    if (self.model_name.startswith(\"bert\")) or (self.model_name.startswith(\"roberta\")):\n",
    "                        all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index]).numpy()\n",
    "                    if self.model_name.startswith(\"gpt\") or self.model_name.startswith(\"xlnet\"):\n",
    "                        all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index - 1]).numpy()\n",
    "\n",
    "                    probabilities_fillers.append(all_probabilities[self.tokenizer.convert_tokens_to_ids(target_word)])\n",
    "                    \"\"\"\n",
    "                    idxs_predictions = (-(np.array(all_probabilities))).argsort()[:N_PREDICTIONS]\n",
    "                    predictions = self.tokenizer.convert_ids_to_tokens([int(index) for index in idxs_predictions])\n",
    "                    string_predicted_fillers = \"\"\n",
    "                    for word, index in zip(predictions, idxs_predictions):\n",
    "                        string_predicted_fillers += word.replace(\"Ġ\", \"\")+\"_(\"+str(all_probabilities[index])+\")\"+\";\"\n",
    "                    predicted_fillers.append(string_predicted_fillers)\n",
    "                    \"\"\"\n",
    "            return probabilities_fillers#, predicted_fillers    \n",
    "        \n",
    "        else:    \n",
    "            probabilities_uni_fillers = []\n",
    "            predicted_uni_fillers = []\n",
    "            \n",
    "            new_attention_mask = []\n",
    "            for mask, id, sent in zip(inputs[\"attention_mask\"], list_dependents_indexes, list_masked_sentences):\n",
    "                mask_array = np.array([0 for elem in mask])\n",
    "                for i in range(0, id+1):\n",
    "                    mask_array[i] = 1\n",
    "                new_attention_mask.append(tf.convert_to_tensor(mask_array))\n",
    "            inputs[\"attention_mask\"] = tf.convert_to_tensor(new_attention_mask)\n",
    "            #print(\"Executing model for batch...\")\n",
    "            #print()\n",
    "            outputs = self.mlm_model(inputs)[0]\n",
    "            for batch_elem, target_word, dep_index in zip(range(outputs.shape[0]), list_target_words,\n",
    "                                                          list_dependents_indexes):\n",
    "                #if target_word is None:\n",
    "                #    probabilities_uni_fillers.append(None)\n",
    "                if type(target_word) == list: # word is OOV, get its subcomponents probability and average them\n",
    "                    prob_subwords = []\n",
    "                    for target_subword in target_word:\n",
    "                        if (self.model_name.startswith(\"bert\")) or (self.model_name.startswith(\"roberta\")):\n",
    "                            all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index]).numpy()\n",
    "                        if self.model_name.startswith(\"gpt\") or self.model_name.startswith(\"xlnet\"):\n",
    "                            all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index - 1]).numpy()\n",
    "                        \n",
    "                        prob_subwords.append(all_probabilities[self.tokenizer.convert_tokens_to_ids(target_subword)])\n",
    "                    probabilities_uni_fillers.append(sum(prob_subwords)/len(prob_subwords))\n",
    "                else:\n",
    "                    if (self.model_name.startswith(\"bert\")) or (self.model_name.startswith(\"roberta\")):\n",
    "                        all_probabilities = tf.nn.softmax(outputs[batch_elem, dep_index]).numpy()\n",
    "                    if self.model_name.startswith(\"gpt\") or self.model_name.startswith(\"xlnet\"):\n",
    "                        all_probabilities = tf.nn.softmax(outputs[batch_elem, 0]).numpy()\n",
    "                    probabilities_uni_fillers.append(all_probabilities[self.tokenizer.convert_tokens_to_ids(target_word)])\n",
    "        \n",
    "            return probabilities_uni_fillers#, predicted_fillers, probabilities_unidirectional\n",
    "    \n",
    "    \n",
    "    def run_prediction(self, data_sequences, indexes, unilateral, batch_dimension=64):\n",
    "        num_sentences = len(data_sequences)\n",
    "        if num_sentences % batch_dimension == 0:\n",
    "            num_batches = num_sentences // batch_dimension\n",
    "        else:\n",
    "            num_batches = num_sentences // batch_dimension + 1\n",
    "        total_scores = []\n",
    "        total_best_fillers = []\n",
    "        total_uni_scores = []\n",
    "        for batch in range(num_batches):\n",
    "            #print()\n",
    "            #print(\"Processing batch {} of {} . Progress: {} ...\".format(batch + 1, num_batches,\n",
    "            #                                                                  np.round((100 / num_batches) * (batch + 1)\n",
    "            #                                                                           , 2)))\n",
    "            if batch != num_batches - 1:\n",
    "                target_words, masked_sentences, positions_dependents = self.\\\n",
    "                    prepare_input(data_sequences[batch * batch_dimension: (batch + 1) * batch_dimension], indexes)\n",
    "                scores = self.compute_filler_probability(target_words, masked_sentences, \n",
    "                                                                                positions_dependents, unilateral)\n",
    "            else:\n",
    "                target_words, masked_sentences, positions_dependents = self.\\\n",
    "                    prepare_input(data_sequences[batch * batch_dimension:], indexes)\n",
    "                scores = self.compute_filler_probability(target_words, masked_sentences,\n",
    "                                                                       positions_dependents, unilateral)\n",
    "            total_scores.extend(scores)\n",
    "            #total_best_fillers.extend(best_fillers)\n",
    "            #total_uni_scores.extend(uni_scores)\n",
    "            \n",
    "        return total_scores#, total_best_fillers, total_uni_scores\n",
    "        \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-saying",
   "metadata": {},
   "source": [
    "## 1. Verb prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0184189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_word(sentences):\n",
    "    model_probs = model.run_prediction(sentences, pos, False, BATCH_SIZE)\n",
    "    log_probs = [math.log(x) for x in model_probs]\n",
    "    return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cellular-publication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 The call girl wasted the money . -8.309730336734093\n",
      "1 The money wasted the call girl . -11.48610186565477\n",
      "2 The money was wasted by the call girl . -7.5881486016313255\n",
      "3 The call girl was wasted by the money . -12.116192969350232\n",
      "4 The ship captain promised the triumph . -8.101441599734544\n",
      "5 The triumph promised the ship captain . -16.524198769552555\n",
      "6 The triumph was promised by the ship captain . -8.006695399430026\n",
      "7 The ship captain was promised by the triumph . -11.176496221663607\n",
      "8 The drapes were suggested by the designer . -5.518226965316399\n",
      "9 The designer was suggested by the drapes . -8.229248007456546\n",
      "10 The curtains were recommended by the decorator . -5.322967021876008\n",
      "11 The decorator was recommended by the curtains . -9.97206855899891\n",
      "12 The builder were washed by the pants . -8.684476626137199\n",
      "13 The contractor was laundered by the trousers . -16.545714039832564\n",
      "14 The domestic cleaned the wash basin . -6.717896513209209\n",
      "15 The wash basin cleaned the domestic . -11.050662415469455\n",
      "16 The wash basin was cleaned by the domestic . -6.8244406567315\n",
      "17 The domestic was cleaned by the wash basin . -6.924434784509472\n",
      "18 The logger felled the pine tree . -16.256724799479375\n",
      "19 The pine tree felled the logger . -15.988495440728377\n",
      "20 The pine tree was felled by the logger . -15.972120811033898\n",
      "21 The logger was felled by the pine tree . -18.31872407383705\n",
      "22 The proprietor dislodged the renter . -15.987272217594631\n",
      "23 The renter dislodged the proprietor . -15.734983708011791\n",
      "24 The renter was dislodged by the proprietor . -17.139801281136947\n",
      "25 The proprietor was dislodged by the renter . -16.744669351360358\n",
      "26 The hit man killed the politician . -2.66748793774646\n",
      "27 The politician killed the hit man . -4.052262568625107\n",
      "28 The politician was killed by the hit man . -1.1513108365704308\n",
      "29 The hit man was killed by the politician . -1.1685816372670437\n",
      "30 The clerk charged the elderly person . -7.3131749968551505\n",
      "31 The elderly person charged the clerk . -7.532510338661586\n",
      "32 The elderly person was charged by the clerk . -6.676716235781161\n",
      "33 The clerk was charged by the elderly person . -7.160611329832098\n",
      "34 The cashier billed the senior citizen . -10.186435904751859\n",
      "35 The senior citizen billed the cashier . -11.584878492499838\n",
      "36 The senior citizen was billed by the cashier . -8.382355297454616\n",
      "37 The cashier was billed by the senior citizen . -9.645551934305438\n",
      "38 The orator was captivated by the spectators . -18.46099954377377\n",
      "39 The amateur irked the maestro . -16.76298890898402\n",
      "40 The maestro irked the amateur . -17.844929975317598\n",
      "41 The maestro was irked by the amateur . -13.68538604188116\n",
      "42 The amateur was irked by the maestro . -14.776768597458885\n",
      "43 The viewers were entranced by the illusionist . -16.497753529487827\n",
      "44 The illusionist was entranced by the viewers . -17.353500537270076\n",
      "45 The terrorist petrified the first lady . -16.7599548226657\n",
      "46 The first lady petrified the terrorist . -16.079247643460512\n",
      "47 The first lady was petrified by the terrorist . -16.782788074340893\n",
      "48 The terrorist was petrified by the first lady . -16.38613914246308\n",
      "49 The hijacker terrified the president's wife . -8.543437375191548\n",
      "50 The president's wife terrified the hijacker . -9.807311702330862\n",
      "51 The president's wife was terrified by the hijacker . -9.777090402337716\n",
      "52 The hijacker was terrified by the president's wife . -9.904820256735823\n",
      "53 The judge praised the gold medalist . -4.477527843257805\n",
      "54 The gold medalist praised the judge . -6.271007006328232\n",
      "55 The gold medalist was praised by the judge . -4.497362946765759\n",
      "56 The judge was praised by the gold medalist . -3.483067461271218\n",
      "57 The ancestors were idolized by the peasant . -13.457320122292009\n",
      "58 The peasant were idolized by the ancestors . -13.75630369967959\n",
      "59 The forefathers were worshipped by the serf . -7.602386993866674\n",
      "60 The serf were worshipped by the forefathers . -6.405574828213963\n",
      "61 The traveling salesman challenged the executive . -8.922582875950496\n",
      "62 The executive challenged the traveling salesman . -7.767929673920337\n",
      "63 The executive was challenged by the traveling salesman . -6.382101260604971\n",
      "64 The traveling salesman was challenged by the executive . -6.556257219552432\n",
      "65 The instrumentalist adored the prima donna . -16.485749149567408\n",
      "66 The prima donna adored the instrumentalist . -15.746216678565528\n",
      "67 The prima donna was adored by the instrumentalist . -13.195683604406417\n",
      "68 The instrumentalist was adored by the prima donna . -12.752231989927482\n",
      "69 The residents were angered by the dictator . -7.084300305657553\n",
      "70 The dictator was angered by the residents . -7.659696496947062\n",
      "71 The townspeople were enraged by the despot . -6.074722640013828\n",
      "72 The despot was enraged by the townspeople . -8.065801451318821\n",
      "73 The refugee provoked the homeless person . -13.030759875486785\n",
      "74 The homeless person provoked the refugee . -12.923791508459633\n",
      "75 The homeless person was provoked by the refugee . -8.00162108297462\n",
      "76 The refugee was provoked by the homeless person . -7.681145131531321\n",
      "77 The asylum seeker goaded the vagrant . -17.34401370981818\n",
      "78 The vagrant goaded the asylum seeker . -17.36456062812928\n",
      "79 The vagrant was goaded by the asylum seeker . -17.80377385227625\n",
      "80 The asylum seeker was goaded by the vagrant . -17.8864710735531\n",
      "81 The runner encountered the co-worker . -5.27161499962395\n",
      "82 The co-worker encountered the runner . -4.880656160664958\n",
      "83 The co-worker was encountered by the runner . -6.694704402680623\n",
      "84 The runner was encountered by the co-worker . -6.445863272210215\n",
      "89 The postal worker repulsed the taxi-driver . -13.695070342853619\n",
      "90 The taxi-driver repulsed the postal worker . -13.541645408109805\n",
      "91 The taxi-driver was repulsed by the postal worker . -13.84411969668529\n",
      "92 The postal worker was repulsed by the taxi-driver . -14.459475710214884\n",
      "93 The letter carrier disgusted the cabbie . -13.069263892330358\n",
      "94 The cabbie disgusted the letter carrier . -13.078149404348862\n",
      "95 The cabbie was disgusted by the letter carrier . -5.832438240578556\n",
      "96 The letter carrier was disgusted by the cabbie . -7.089731606598681\n",
      "97 The officer were alerted by the authorities . -8.56911981562563\n",
      "98 The deputy was notified by the higher-ups . -7.204885477696225\n",
      "99 The perpetrator exposed the poacher . -7.945271287852473\n",
      "100 The poacher exposed the perpetrator . -7.502253464676029\n",
      "101 The poacher was exposed by the perpetrator . -7.957205062588594\n",
      "102 The perpetrator was exposed by the poacher . -6.999329274400532\n",
      "103 The flora specialist esteemed the collaborator . -13.843046457741288\n",
      "104 The collaborator esteemed the flora specialist . -13.725489859038351\n",
      "105 The collaborator was esteemed by the flora specialist . -10.826569321477995\n",
      "106 The flora specialist was esteemed by the collaborator . -10.21195151577611\n",
      "107 The rogue defeated the main character . -8.119284608366177\n",
      "108 The main character defeated the rogue . -12.025826550401819\n",
      "109 The main character was defeated by the rogue . -2.7605229636148456\n",
      "110 The rogue was defeated by the main character . -0.8356734308913527\n",
      "117 The rules were emphasized by the counselor . -7.7358171929907185\n",
      "118 The counselor was emphasized by the rules . -13.138251612167466\n",
      "123 The laundress were folded by the clothes . -8.951523542100643\n",
      "124 The groundskeeper changed the light bulb . -1.8161789711461036\n",
      "125 The light bulb changed the groundskeeper . -6.874271457459791\n",
      "126 The light bulb was changed by the groundskeeper . -1.8891754914910688\n",
      "127 The groundskeeper was changed by the light bulb . -9.860233202261352\n",
      "128 The house sitter watered the plant . -3.863712734042851\n",
      "129 The plant watered the house sitter . -11.3872109015019\n",
      "130 The plant was watered by the house sitter . -3.1752881583298187\n",
      "131 The house sitter was watered by the plant . -15.531472027301879\n",
      "132 The twins were punished by the babysitter . -7.994465059099072\n",
      "133 The babysitter was punished by the twins . -7.167705182588269\n",
      "134 The barber shaved the old man . -6.995340118332426\n",
      "135 The old man shaved the barber . -10.15830928833059\n",
      "136 The old man was shaved by the barber . -8.559441269345834\n",
      "137 The barber was shaved by the old man . -10.294320515703463\n",
      "138 The paparazzi stalked the pop star . -12.531599580432875\n",
      "139 The pop star stalked the paparazzi . -14.62412704498304\n",
      "140 The pop star was stalked by the paparazzi . -13.17181173737525\n",
      "141 The paparazzi was stalked by the pop star . -13.655054476315797\n",
      "142 The personal trainer weighed the Olympian . -12.622551273096137\n",
      "143 The Olympian weighed the personal trainer . -11.032030142963501\n",
      "144 The Olympian was weighed by the personal trainer . -7.938412948566747\n",
      "145 The personal trainer was weighed by the Olympian . -12.115257511933693\n",
      "146 The tennis player thanked the chiropractor . -6.131050153513803\n",
      "147 The chiropractor thanked the tennis player . -9.313116077009942\n",
      "148 The chiropractor was thanked by the tennis player . -4.8803762031295905\n",
      "149 The tennis player was thanked by the chiropractor . -7.470156333200369\n",
      "150 The assistant principal expelled the sociopath . -9.360448273702193\n",
      "151 The sociopath expelled the assistant principal . -10.140927779850415\n",
      "152 The sociopath was expelled by the assistant principal . -4.949960678380654\n",
      "153 The assistant principal was expelled by the sociopath . -6.057094189883132\n",
      "154 The au pair spanked the girl . -16.871497307056906\n",
      "155 The girl spanked the au pair . -17.88462498960749\n",
      "156 The girl was spanked by the au pair . -16.136323106781788\n",
      "157 The au pair was spanked by the girl . -17.16353882932286\n",
      "158 The TV station head promoted the newsagent . -10.312906060217722\n",
      "159 The newsagent promoted the TV station head . -9.845291960474519\n",
      "160 The newsagent was promoted by the TV station head . -7.3946122719782315\n",
      "161 The TV station head was promoted by the newsagent . -8.332372341365945\n",
      "162 The police chief rewarded the firefighter . -8.793802302073296\n",
      "163 The firefighter rewarded the police chief . -10.677880104380067\n",
      "164 The firefighter was rewarded by the police chief . -6.598935010351258\n",
      "165 The police chief was rewarded by the firefighter . -9.420977888777456\n",
      "166 The social worker comforted the abused woman . -13.092456425896792\n",
      "166 The social worker comforted the abused woman . -4.8580880757033045\n",
      "167 The abused woman comforted the social worker . -6.169795744261671\n",
      "167 The abused woman comforted the social worker . -13.12926753843668\n",
      "168 The abused woman was comforted by the social worker . -4.804304285135812\n",
      "168 The abused woman was comforted by the social worker . -14.769002685808763\n",
      "169 The social worker was comforted by the abused woman . -14.34539553775896\n",
      "169 The social worker was comforted by the abused woman . -6.148843155518463\n",
      "170 The neuroscientist overwhelmed the lab assistant . -12.40829915498838\n",
      "171 The lab assistant overwhelmed the neuroscientist . -11.101902411989004\n",
      "172 The lab assistant was overwhelmed by the neuroscientist . -6.537684892484284\n",
      "173 The neuroscientist was overwhelmed by the lab assistant . -6.027531869258686\n",
      "174 The football player pursued the socialite . -9.031667530132925\n",
      "175 The socialite pursued the football player . -9.270126325593079\n",
      "176 The socialite was pursued by the football player . -5.577214747826501\n",
      "177 The football player was pursued by the socialite . -4.843217326390107\n",
      "178 The fashionista humiliated the model . -12.061678337873708\n",
      "179 The model humiliated the fashionista . -11.378739271215307\n",
      "180 The model was humiliated by the fashionista . -6.865638563866176\n",
      "181 The fashionista was humiliated by the model . -6.0567082013225715\n",
      "182 The claims adjuster harassed the retailer . -10.264641795800612\n",
      "183 The retailer harassed the claims adjuster . -10.536570006993529\n",
      "184 The retailer was harassed by the claims adjuster . -10.466157022611856\n",
      "185 The claims adjuster was harassed by the retailer . -10.95261825766892\n",
      "186 The cinematographer favored the movie star . -9.197924322321903\n",
      "187 The movie star favored the cinematographer . -10.948331379368659\n",
      "188 The movie star was favored by the cinematographer . -8.449602138295448\n",
      "189 The cinematographer was favored by the movie star . -6.489605087764677\n",
      "190 The hockey player aggravated the skater . -14.667336829396497\n",
      "191 The skater aggravated the hockey player . -13.824932149748443\n",
      "192 The skater was aggravated by the hockey player . -10.46359431324679\n",
      "193 The hockey player was aggravated by the skater . -10.813050811224848\n",
      "194 The bricklayer outraged the crane operator . -15.671806027010039\n",
      "195 The crane operator outraged the bricklayer . -16.132680352283018\n",
      "196 The crane operator was outraged by the bricklayer . -7.677300664359389\n",
      "197 The bricklayer was outraged by the crane operator . -9.409469640860085\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "model = TransformerModel('roberta-large')\n",
    "probs = mask_word(sentences)\n",
    "\n",
    "for i, sent, score in zip(idxs_sent,sentences, probs):\n",
    "    print(i, sent, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-quilt",
   "metadata": {},
   "source": [
    "## 2. Sequential word prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-scottish",
   "metadata": {},
   "source": [
    "### 2.1 Pseudo-log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47c36a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_word_by_word(sentences):\n",
    "    results = []\n",
    "    for sent in sentences:\n",
    "        s = sent.split(' ')\n",
    "        ids = [w_id for w_id in range(0, len(s))]\n",
    "        ss = [sent for i in range(0, len(s))]    \n",
    "        # run model\n",
    "        model_probs = model.run_prediction(ss, ids, False, BATCH_SIZE)\n",
    "\n",
    "        try:\n",
    "            results.append((sent, sum(model_probs)))\n",
    "        except TypeError:\n",
    "            results.append((sent, None))\n",
    "            \n",
    "    log_probs = [math.log(x) for x in results]\n",
    "    return log_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901e748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "model = TransformerModel('roberta-large')\n",
    "probs = mask_word_by_word(sentences)\n",
    "\n",
    "for i, sent, score in zip(idxs_sent, sentences, probs):\n",
    "    print(i, sent, score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-sheet",
   "metadata": {},
   "source": [
    "### 2.2 Left-to-right generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "manual-recipe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "def mask_word_left2right(sentences):\n",
    "    results = []\n",
    "    for sent in tqdm(sentences):\n",
    "        s = sent.split(' ')\n",
    "        ids = [w_id for w_id in range(0, len(s))]\n",
    "        ss = [sent for i in range(0, len(s))]  \n",
    "        model_probs = model.run_prediction(ss, ids, True, BATCH_SIZE)\n",
    "        #try:\n",
    "        results.append((sent, sum(model_probs)))\n",
    "        #except TypeError:\n",
    "        #    results.append((sent, None))\n",
    "    log_probs = [math.log(x[1]) for x in results]\n",
    "    return log_probs\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f5a14cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [02:18<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "out_folder = 'left2right_res/'\n",
    "model = TransformerModel('bert-large-cased')\n",
    "ids, sents=prepare_data(new_ev)\n",
    "d='new-EventsAdapt'\n",
    "probs = mask_word_left2right(sents)\n",
    "with open(os.path.join(out_folder, d+'.'+'bert-large-cased.l2r.txt'), 'w') as fout:\n",
    "    for i, sent,score in zip(ids,sents,probs):\n",
    "        fout.write('{}\\t{}\\t{}\\n'.format(i, sent,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "925ae046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ev1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 6/80 [00:05<01:05,  1.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-71c3a91d1d99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_word_left2right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'xlnet-large-cased.l2r.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-6198d498aeef>\u001b[0m in \u001b[0;36mmask_word_left2right\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw_id\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msent\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-2b6756a6555e>\u001b[0m in \u001b[0;36mrun_prediction\u001b[0;34m(self, data_sequences, indexes, unilateral, batch_dimension)\u001b[0m\n\u001b[1;32m    223\u001b[0m                     \u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_dimension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 scores = self.compute_filler_probability(target_words, masked_sentences,\n\u001b[0;32m--> 225\u001b[0;31m                                                                        positions_dependents, unilateral)\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0mtotal_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;31m#total_best_fillers.extend(best_fillers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-2b6756a6555e>\u001b[0m in \u001b[0;36mcompute_filler_probability\u001b[0;34m(self, list_target_words, list_masked_sentences, list_dependents_indexes, unidirectional)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m#print(\"Executing model for batch...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m#print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             for batch_elem, target_word, dep_index in zip(range(outputs.shape[0]), list_target_words,\n\u001b[1;32m    179\u001b[0m                                                           list_dependents_indexes):\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, labels, training, **kwargs)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         )\n\u001b[1;32m   1374\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_ids, attention_mask, mems, perm_mask, target_mapping, token_type_ids, input_mask, head_mask, inputs_embeds, use_mems, output_attentions, output_hidden_states, return_dict, training, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"head_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_attentions\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m             )\n\u001b[1;32m    778\u001b[0m             \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, output_h, output_g, non_tgt_mask, attn_mask, pos_emb, seg_mat, mems, target_mapping, head_mask, output_attentions, training)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         )\n\u001b[1;32m    390\u001b[0m         \u001b[0moutput_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, h, g, attn_mask_h, attn_mask_g, r, seg_mat, mems, target_mapping, head_mask, output_attentions, training)\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             )\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/transformers/models/xlnet/modeling_tf_xlnet.py\u001b[0m in \u001b[0;36mrel_attn_core\u001b[0;34m(self, q_head, k_head_h, v_head_h, k_head_r, seg_mat, attn_mask, head_mask, output_attentions, training)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;34m\"\"\"Core relative positional attention operations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# content based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ibnd,jbnd->ijbn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_head\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_w_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_head_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# position based attention score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;34m-\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mare\u001b[0m \u001b[0minconsistent\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \"\"\"\n\u001b[0;32m--> 751\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_einsum_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/ops/special_math_ops.py\u001b[0m in \u001b[0;36m_einsum_v2\u001b[0;34m(equation, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moperand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m         \u001b[0minput_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;31m# `_tensor_shape` is declared and defined in the definition of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers_thematic_fit/venv_ttf/lib/python3.6/site-packages/tensorflow-2.4.1-py3.6-linux-x86_64.egg/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "out_folder = 'left2right_res/'\n",
    "model_name = 'xlnet-large-cased'\n",
    "model = TransformerModel(model_name)\n",
    "for d in datasets:\n",
    "    print(d)\n",
    "    ids, sents = datasets[d]\n",
    "    probs = mask_word_left2right(sents)\n",
    "    with open(os.path.join(out_folder, '{}.{}.l2r.txt'.format(d, model_name)), 'w') as fout:\n",
    "        for i, sent,score in zip(ids,sents,probs):\n",
    "            fout.write('{}\\t{}\\t{}\\n'.format(i, sent,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bc6427c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel('bert-large-cased')\n",
    "f=['The babysitter won the game .']\n",
    "for sent in f:\n",
    "    s = sent.split(' ')\n",
    "    ids = [w_id for w_id in range(0, len(s)-1)]\n",
    "    ss = [sent for i in range(0, len(s)-1)]  \n",
    "    #x=model.prepare_input(ss, ids)\n",
    "    #print(x)\n",
    "    model_probs = model.run_prediction(ss, ids, True, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed905fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.810984778778033, -13.074512794218947, -8.56862631496403, -2.4878174728260043, -6.106897208303697]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print([math.log(x) for x in model_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac8cd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baby', '##si', '##tter']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.tokenize('babysitter')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
